{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3426692,"sourceType":"datasetVersion","datasetId":2065225}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport cv2 \nfrom skimage import morphology\nfrom skimage.filters import threshold_multiotsu\n\ndef augment_image(file_path, threshold_val):\n    file_contents = tf.io.read_file(file_path)\n    image = tf.io.decode_image(file_contents, channels=1, dtype=tf.uint8)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n\n    image = tf.image.resize(image, [224, 224])\n\n    # 3) Data augmentation\n    # Only adjust brightness if random uniform > threshold.\n    if tf.random.uniform(()) > threshold_val:\n        image = tf.image.flip_left_right(image)\n\n    # Losowo zdecyduj, czy zastosować obrót o 90 stopni\n    if tf.random.uniform(()) > threshold_val:\n        k = tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)\n        image = tf.image.rot90(image, k=k)\n\n    # Losowa zmiana jasności\n    if tf.random.uniform(()) > threshold_val:\n        delta = tf.random.uniform((), minval=-0.2, maxval=0.2)\n        image = tf.image.adjust_brightness(image, delta)\n    \n    image_uint8 = tf.image.convert_image_dtype(image, tf.uint8)\n    encoded_image = tf.io.encode_jpeg(image_uint8)\n    tf.io.write_file(file_path, encoded_image)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:43:25.937456Z","iopub.execute_input":"2025-04-06T10:43:25.937713Z","iopub.status.idle":"2025-04-06T10:43:45.123257Z","shell.execute_reply.started":"2025-04-06T10:43:25.937693Z","shell.execute_reply":"2025-04-06T10:43:45.122442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_image(image_path):\n    \"\"\"\n    Loads the image from `image_path`, performs:\n      1. Standardization\n      2. Normalization\n      3. Watershed segmentation\n      4. Multilevel thresholding\n    and saves the final processed image back to the same file path.\n    \"\"\"\n    # 1) LOAD the image via TensorFlow\n    file_contents = tf.io.read_file(image_path)\n    # Decode as a single-channel image (grayscale). \n    # If your images are actually RGB, set channels=3 instead.\n    img = tf.io.decode_image(file_contents, channels=1, dtype=tf.float32)\n    img = tf.image.resize(img, [224, 224])\n    # ----------------------------------------------------------------\n    # 2) STANDARDIZATION (z-score: zero mean, unit variance)\n    #    per_image_standardization does: (x - mean) / adjusted_stddev\n    # ----------------------------------------------------------------\n    standardized = tf.image.per_image_standardization(img)\n\n    # ----------------------------------------------------------------\n    # 3) NORMALIZATION (scale pixels to [0,1])\n    # ----------------------------------------------------------------\n    std_np = standardized.numpy().squeeze() \n    min_val, max_val = std_np.min(), std_np.max()\n    normalized_np = (std_np - min_val) / (max_val - min_val + 1e-8)\n\n    # ----------------------------------------------------------------\n    # 4) WATERSHED SEGMENTATION\n    #    We'll create a simple binary mask using Otsu's threshold\n    #    and then apply the watershed algorithm.\n    # ----------------------------------------------------------------\n    # ...\n    otsu_thresh = filters.threshold_otsu(normalized_np)\n    binary_mask = normalized_np > otsu_thresh\n    distance = ndimage.distance_transform_edt(binary_mask)\n\n    # Step 1: get peak coordinates (Nx2 array)\n    coords = peak_local_max(distance, min_distance=10, labels=binary_mask)\n\n    # Step 2: build a boolean mask from these coordinates\n    local_max_mask = np.zeros_like(distance, dtype=bool)\n    local_max_mask[coords[:, 0], coords[:, 1]] = True\n\n    # Step 3: label the maxima\n    markers = ndimage.label(local_max_mask)[0]\n\n    # Step 4: perform watershed\n    labels_ws = watershed(-distance, markers, mask=binary_mask)\n\n    # ----------------------------------------------------------------\n    # 5) MULTI-LEVEL THRESHOLDING\n    #    We'll separate the normalized image into three classes as example.\n    #    Increase or decrease `classes` parameter as needed.\n    # ----------------------------------------------------------------\n    thresholds = threshold_multiotsu(normalized_np, classes=3)\n    multi_thresh_img = np.digitize(normalized_np, bins=thresholds)\n\n    # ----------------------------------------------------------------\n    # Choose how you want the final image to look:\n    # For demonstration, we'll take the multi-level thresholding result\n    # as the final output. You might also combine or visualize watershed\n    # differently. Feel free to adapt as necessary.\n    # ----------------------------------------------------------------\n    final_img_np = (multi_thresh_img * 127).astype(np.uint8)\n\n    # Re-encode via TensorFlow and overwrite\n    final_img_tf = tf.expand_dims(tf.convert_to_tensor(final_img_np), axis=-1)\n    encoded_img = tf.io.encode_png(final_img_tf)\n    out_filepath = image_path.replace(\"/kaggle/input\", \"/kaggle/working\")\n    tf.io.write_file(out_filepath, encoded_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:43:45.124284Z","iopub.execute_input":"2025-04-06T10:43:45.124786Z","iopub.status.idle":"2025-04-06T10:43:45.132621Z","shell.execute_reply.started":"2025-04-06T10:43:45.12476Z","shell.execute_reply":"2025-04-06T10:43:45.131761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\n\nfrom skimage import filters\nfrom skimage.filters import threshold_multiotsu\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:43:45.133929Z","iopub.execute_input":"2025-04-06T10:43:45.134199Z","iopub.status.idle":"2025-04-06T10:43:45.724392Z","shell.execute_reply.started":"2025-04-06T10:43:45.134178Z","shell.execute_reply":"2025-04-06T10:43:45.72368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        in_path = os.path.join(dirname, filename)\n        if os.path.getsize(in_path) == 0:\n            print(f\"Skipping empty file: {in_path}\")\n        else:    \n            print(os.path.join(dirname, filename))\n            out_path = in_path.replace(\"/kaggle/input\", \"/kaggle/working\")\n            process_image(in_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:43:45.725682Z","iopub.execute_input":"2025-04-06T10:43:45.726294Z","iopub.status.idle":"2025-04-06T10:45:40.716389Z","shell.execute_reply.started":"2025-04-06T10:43:45.726261Z","shell.execute_reply":"2025-04-06T10:45:40.715675Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\ntrain_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train\"\ntrain_40_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntrain_70_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\n\nif os.path.exists(train_40_set):\n    shutil.rmtree(train_40_set)  # remove the existing directory\nshutil.copytree(train_set, train_40_set)\nif os.path.exists(train_70_set):\n    shutil.rmtree(train_70_set)  # remove the existing directory\nshutil.copytree(train_set, train_70_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:45:40.717245Z","iopub.execute_input":"2025-04-06T10:45:40.717494Z","iopub.status.idle":"2025-04-06T10:45:41.126559Z","shell.execute_reply.started":"2025-04-06T10:45:40.717473Z","shell.execute_reply":"2025-04-06T10:45:41.125839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def call_train_set(train_set, threshhold):\n    for dirname, _, filenames in os.walk(train_set):\n        for filename in filenames:\n            in_path = os.path.join(dirname, filename)\n            augment_image(in_path, threshhold)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:45:41.12732Z","iopub.execute_input":"2025-04-06T10:45:41.127637Z","iopub.status.idle":"2025-04-06T10:45:41.131361Z","shell.execute_reply.started":"2025-04-06T10:45:41.127613Z","shell.execute_reply":"2025-04-06T10:45:41.130566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"call_train_set(train_40_set, 0.4)\ncall_train_set(train_70_set, 0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:45:41.132287Z","iopub.execute_input":"2025-04-06T10:45:41.132571Z","iopub.status.idle":"2025-04-06T10:45:59.86902Z","shell.execute_reply.started":"2025-04-06T10:45:41.132543Z","shell.execute_reply":"2025-04-06T10:45:59.868112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\naugmentation_counts = {\n    \"flip\": 0,\n    \"rotate\": 0,\n    \"brightness\": 0,\n    \"at_least_two\": 0,\n    \"all_three\": 0\n}\n\nexample_images = {\n    \"flip\": [],\n    \"rotate\": [],\n    \"brightness\": [],\n    \"at_least_two\": [],\n    \"all_three\": []\n}\n\ndef augment_image(file_path, threshold_val):\n    file_contents = tf.io.read_file(file_path)\n    image = tf.io.decode_image(file_contents, channels=1, dtype=tf.uint8)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n\n    applied_augmentations = []\n\n    # Flip\n    if tf.random.uniform(()) > threshold_val:\n        image = tf.image.flip_left_right(image)\n        applied_augmentations.append(\"flip\")\n\n    # Rotate\n    if tf.random.uniform(()) > threshold_val:\n        k = tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)\n        image = tf.image.rot90(image, k=k)\n        applied_augmentations.append(\"rotate\")\n\n    # Brightness\n    if tf.random.uniform(()) > threshold_val:\n        delta = tf.random.uniform((), minval=-0.2, maxval=0.2)\n        image = tf.image.adjust_brightness(image, delta)\n        applied_augmentations.append(\"brightness\")\n\n    for aug in applied_augmentations:\n        augmentation_counts[aug] += 1\n    \n    if len(applied_augmentations) >= 2:\n        augmentation_counts[\"at_least_two\"] += 1\n    \n    if len(applied_augmentations) == 3:\n        augmentation_counts[\"all_three\"] += 1\n\n    for aug in applied_augmentations:\n        if len(example_images[aug]) < 4:\n            example_images[aug].append(image.numpy())\n    \n    if len(applied_augmentations) >= 2 and len(example_images[\"at_least_two\"]) < 4:\n        example_images[\"at_least_two\"].append(image.numpy())\n    \n    if len(applied_augmentations) == 3 and len(example_images[\"all_three\"]) < 4:\n        example_images[\"all_three\"].append(image.numpy())\n    \n    image_uint8 = tf.image.convert_image_dtype(image, tf.uint8)\n    encoded_image = tf.io.encode_jpeg(image_uint8)\n    tf.io.write_file(file_path, encoded_image)\n\ndef call_train_set(train_set, threshhold):\n    for dirname, _, filenames in os.walk(train_set):\n        for filename in filenames:\n            in_path = os.path.join(dirname, filename)\n            augment_image(in_path, threshhold)\n\ndef display_images():\n    fig, axes = plt.subplots(5, 4, figsize=(15, 15))\n    titles = [\"flip\", \"rotate\", \"brightness\", \"at_least_two\", \"all_three\"]\n    \n    for i, key in enumerate(titles):\n        for j in range(4):\n            if j < len(example_images[key]):\n                axes[i, j].imshow(example_images[key][j].squeeze(), cmap='gray')\n            axes[i, j].set_title(f\"{key} {j+1}\")\n            axes[i, j].axis(\"off\")\n    \n    plt.show()\n\ntrain_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train\"\ntrain_40_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntrain_70_set = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\n\ncall_train_set(train_40_set, 0.4)\ncall_train_set(train_70_set, 0.7)\n\nprint(\"Statystyki augmentacji:\")\nfor key, value in augmentation_counts.items():\n    print(f\"{key}: {value}\")\n\ndisplay_images()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:45:59.870923Z","iopub.execute_input":"2025-04-06T10:45:59.871168Z","iopub.status.idle":"2025-04-06T10:46:19.070754Z","shell.execute_reply.started":"2025-04-06T10:45:59.871148Z","shell.execute_reply":"2025-04-06T10:46:19.069505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"segmented_images = {\n    \"segmented\": []\n}\n\ndef preprocess_image(image_path):\n    file_contents = tf.io.read_file(image_path)\n    img = tf.io.decode_image(file_contents, channels=1, dtype=tf.uint8)\n    img = tf.image.resize(img, [224, 224])\n    img_np = img.numpy().squeeze().astype(np.uint8)\n    \n    # Gaussian Blur\n    img_np = cv2.GaussianBlur(img_np, (5, 5), 0)\n    \n    # Contrast Enhancement\n    contrast = img_np.max() - img_np.min()\n    if contrast < 50:\n        img_np = cv2.equalizeHist(img_np)\n    \n    # Multilevel Thresholding (directly on the processed image, skipping binarization)\n    thresholds = threshold_multiotsu(img_np, classes=3)\n    segmented = np.digitize(img_np, bins=thresholds)\n    \n    # Morphological Processing\n    segmented = morphology.remove_small_objects(segmented.astype(bool), min_size=30)\n    segmented = morphology.remove_small_holes(segmented, area_threshold=50)\n    \n    final_img_np = (segmented * 127).astype(np.uint8)\n    segmented_images[\"segmented\"].append(final_img_np)\n    \n    final_img_tf = tf.expand_dims(tf.convert_to_tensor(final_img_np), axis=-1)\n    encoded_img = tf.io.encode_png(final_img_tf)\n    out_filepath = image_path.replace(\"/kaggle/input\", \"/kaggle/working\")\n    tf.io.write_file(out_filepath, encoded_img)\n\ndef display_segmented_images():\n    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n    for j in range(4):\n        if j < len(segmented_images[\"segmented\"]):\n            axes[j].imshow(segmented_images[\"segmented\"][j].squeeze(), cmap='gray')\n        axes[j].set_title(f\"Segmented {j+1}\")\n        axes[j].axis(\"off\")\n    plt.show()\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        in_path = os.path.join(dirname, filename)\n        if os.path.getsize(in_path) == 0:\n            print(f\"Skipping empty file: {in_path}\")\n        else:\n            preprocess_image(in_path)\n\ndisplay_segmented_images()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:46:19.072122Z","iopub.execute_input":"2025-04-06T10:46:19.072502Z","iopub.status.idle":"2025-04-06T10:46:56.70349Z","shell.execute_reply.started":"2025-04-06T10:46:19.072464Z","shell.execute_reply":"2025-04-06T10:46:56.702606Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2 \nsegmented_images = {\n    \"blurred\": [],\n    \"contrast_enhanced\": [],\n    \"thresholded\": [],\n    \"morphological\": []\n}\n\ndef preprocess_image(image_path):\n    file_contents = tf.io.read_file(image_path)\n    img = tf.io.decode_image(file_contents, channels=1, dtype=tf.uint8)\n    img = tf.image.resize(img, [224, 224])\n    img_np = img.numpy().squeeze().astype(np.uint8)\n    \n    # Gaussian Blur\n    img_np = cv2.GaussianBlur(img_np, (5, 5), 0)\n    if len(segmented_images[\"blurred\"]) < 4:\n        segmented_images[\"blurred\"].append(img_np)\n    \n    # Contrast Enhancement\n    contrast = img_np.max() - img_np.min()\n    if contrast < 50:\n        img_np = cv2.equalizeHist(img_np)\n    if len(segmented_images[\"contrast_enhanced\"]) < 4:\n        segmented_images[\"contrast_enhanced\"].append(img_np)\n    \n    # Multilevel Thresholding (directly on the processed image, skipping binarization)\n    thresholds = threshold_multiotsu(img_np, classes=3)\n    segmented = np.digitize(img_np, bins=thresholds)\n    if len(segmented_images[\"thresholded\"]) < 4:\n        segmented_images[\"thresholded\"].append((segmented * 127).astype(np.uint8))\n    \n    # Morphological Processing\n    segmented = morphology.remove_small_objects(segmented.astype(bool), min_size=30)\n    segmented = morphology.remove_small_holes(segmented, area_threshold=50)\n    final_img_np = (segmented * 127).astype(np.uint8)\n    \n    if len(segmented_images[\"morphological\"]) < 4:\n        segmented_images[\"morphological\"].append(final_img_np)\n    \n    final_img_tf = tf.expand_dims(tf.convert_to_tensor(final_img_np), axis=-1)\n    encoded_img = tf.io.encode_png(final_img_tf)\n    out_filepath = image_path.replace(\"/kaggle/input\", \"/kaggle/working\")\n    tf.io.write_file(out_filepath, encoded_img)\n\ndef display_segmented_images():\n    stages = [\"blurred\", \"contrast_enhanced\", \"thresholded\", \"morphological\"]\n    fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n    for i, stage in enumerate(stages):\n        for j in range(4):\n            if j < len(segmented_images[stage]):\n                axes[i, j].imshow(segmented_images[stage][j].squeeze(), cmap='gray')\n            axes[i, j].set_title(f\"{stage} {j+1}\")\n            axes[i, j].axis(\"off\")\n    plt.show()\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        in_path = os.path.join(dirname, filename)\n        if os.path.getsize(in_path) == 0:\n            print(f\"Skipping empty file: {in_path}\")\n        else:\n            preprocess_image(in_path)\n\ndisplay_segmented_images()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:46:56.704252Z","iopub.execute_input":"2025-04-06T10:46:56.704521Z","iopub.status.idle":"2025-04-06T10:47:35.575867Z","shell.execute_reply.started":"2025-04-06T10:46:56.704493Z","shell.execute_reply":"2025-04-06T10:47:35.574908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom skimage.feature import hog\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n    image = cv2.resize(image, (128, 128))\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0} \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu k-NN40: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:51:21.316821Z","iopub.execute_input":"2025-04-06T10:51:21.317218Z","iopub.status.idle":"2025-04-06T10:55:08.402808Z","shell.execute_reply.started":"2025-04-06T10:51:21.317192Z","shell.execute_reply":"2025-04-06T10:55:08.402005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n    image = cv2.resize(image, (128, 128))\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0} \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu k-NN70: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:06:03.411337Z","iopub.execute_input":"2025-04-06T11:06:03.412054Z","iopub.status.idle":"2025-04-06T11:09:48.679182Z","shell.execute_reply.started":"2025-04-06T11:06:03.412025Z","shell.execute_reply":"2025-04-06T11:09:48.678151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n    image = cv2.resize(image, (128, 128))  # Skalowanie\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}  \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\nnb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu Naïve Bayes 40: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:11:35.912945Z","iopub.execute_input":"2025-04-06T11:11:35.913291Z","iopub.status.idle":"2025-04-06T11:15:24.202578Z","shell.execute_reply.started":"2025-04-06T11:11:35.913269Z","shell.execute_reply":"2025-04-06T11:15:24.201254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n    image = cv2.resize(image, (128, 128))  # Skalowanie\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}  \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\nnb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu Naïve Bayes 70: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:15:24.204107Z","iopub.execute_input":"2025-04-06T11:15:24.204503Z","iopub.status.idle":"2025-04-06T11:19:15.50914Z","shell.execute_reply.started":"2025-04-06T11:15:24.204465Z","shell.execute_reply":"2025-04-06T11:19:15.50816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n    image = cv2.resize(image, (128, 128))  \n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\n# Funkcja do wczytania obrazów i etykiet\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}  \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\n\nbase_model = DecisionTreeClassifier(max_depth=1)\nadaboost = AdaBoostClassifier(base_model, n_estimators=50, learning_rate=1.0)\nadaboost.fit(X_train, y_train)\n\ny_pred = adaboost.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu AdaBoost 40: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:34:53.41651Z","iopub.execute_input":"2025-04-06T11:34:53.416838Z","iopub.status.idle":"2025-04-06T11:40:12.961312Z","shell.execute_reply.started":"2025-04-06T11:34:53.416814Z","shell.execute_reply":"2025-04-06T11:40:12.960415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\ndef extract_features(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n    image = cv2.resize(image, (128, 128))  \n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True, visualize=True)\n    return features\n\n# Funkcja do wczytania obrazów i etykiet\ndef load_data(directory):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}  \n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            features = extract_features(file_path)\n            X.append(features)\n            y.append(classes[label])\n    return np.array(X), np.array(y)\n\nX_train, y_train = load_data(train_dir)\nX_test, y_test = load_data(test_dir)\n\nbase_model = DecisionTreeClassifier(max_depth=1)\nadaboost = AdaBoostClassifier(base_model, n_estimators=50, learning_rate=1.0)\nadaboost.fit(X_train, y_train)\n\ny_pred = adaboost.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\" Dokładność modelu AdaBoost 70: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:40:12.962434Z","iopub.execute_input":"2025-04-06T11:40:12.962738Z","iopub.status.idle":"2025-04-06T11:45:32.688627Z","shell.execute_reply.started":"2025-04-06T11:40:12.962715Z","shell.execute_reply":"2025-04-06T11:45:32.687815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom skimage.feature import hog, local_binary_pattern\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef extract_color_hist(image_path, bins=(8, 8, 8)):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (128, 128))\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n    return cv2.normalize(hist, hist).flatten()\n\ndef extract_hog(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n                      feature_vector=True, visualize=True)\n    return features\n\ndef extract_lbp(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 59))\n    return hist.astype(\"float\") / (hist.sum() + 1e-6)\n\n\ndef load_data(directory, feature_func):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}\n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            if file_path.endswith(('.jpg', '.png', '.jpeg')):\n                features = feature_func(file_path)\n                X.append(features)\n                y.append(classes[label])\n    return np.array(X), np.array(y)\n\n\n# Ścieżki do danych\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_40\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\n# === Naive Bayes (histogramy kolorów) ===\nX_train_nb, y_train_nb = load_data(train_dir, extract_color_hist)\nX_test_nb, y_test_nb = load_data(test_dir, extract_color_hist)\n\nnb_model = GaussianNB()\nnb_model.fit(X_train_nb, y_train_nb)\npred_nb = nb_model.predict(X_test_nb)\nprint(f\" Naive Bayes 40 (HSV hist): {accuracy_score(y_test_nb, pred_nb):.2f}\")\n\n# === k-NN (HoG) ===\nX_train_knn, y_train_knn = load_data(train_dir, extract_hog)\nX_test_knn, y_test_knn = load_data(test_dir, extract_hog)\n\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train_knn, y_train_knn)\npred_knn = knn_model.predict(X_test_knn)\nprint(f\" k-NN 40 (HoG): {accuracy_score(y_test_knn, pred_knn):.2f}\")\n\n# === AdaBoost (LBP) ===\nX_train_ada, y_train_ada = load_data(train_dir, extract_lbp)\nX_test_ada, y_test_ada = load_data(test_dir, extract_lbp)\n\nada_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50)\nada_model.fit(X_train_ada, y_train_ada)\npred_ada = ada_model.predict(X_test_ada)\nprint(f\" AdaBoost 40 (LBP): {accuracy_score(y_test_ada, pred_ada):.2f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:45:32.690222Z","iopub.execute_input":"2025-04-06T11:45:32.690672Z","iopub.status.idle":"2025-04-06T11:49:37.417785Z","shell.execute_reply.started":"2025-04-06T11:45:32.690641Z","shell.execute_reply":"2025-04-06T11:49:37.416911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom skimage.feature import hog, local_binary_pattern\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ndef extract_color_hist(image_path, bins=(8, 8, 8)):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (128, 128))\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n    return cv2.normalize(hist, hist).flatten()\n\ndef extract_hog(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    features, _ = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n                      feature_vector=True, visualize=True)\n    return features\n\ndef extract_lbp(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 59))\n    return hist.astype(\"float\") / (hist.sum() + 1e-6)\n\n\ndef load_data(directory, feature_func):\n    X, y = [], []\n    classes = {\"infected\": 1, \"notinfected\": 0}\n    for label in classes:\n        folder_path = os.path.join(directory, label)\n        for file in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, file)\n            if file_path.endswith(('.jpg', '.png', '.jpeg')):\n                features = feature_func(file_path)\n                X.append(features)\n                y.append(classes[label])\n    return np.array(X), np.array(y)\n\n\n# Ścieżki do danych\ntrain_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/train_70\"\ntest_dir = \"/kaggle/working/pcos-detection-using-ultrasound-images/data/test\"\n\n# === Naive Bayes (histogramy kolorów) ===\nX_train_nb, y_train_nb = load_data(train_dir, extract_color_hist)\nX_test_nb, y_test_nb = load_data(test_dir, extract_color_hist)\n\nnb_model = GaussianNB()\nnb_model.fit(X_train_nb, y_train_nb)\npred_nb = nb_model.predict(X_test_nb)\nprint(f\" Naive Bayes 70 (HSV hist): {accuracy_score(y_test_nb, pred_nb):.2f}\")\n\n# === k-NN (HoG) ===\nX_train_knn, y_train_knn = load_data(train_dir, extract_hog)\nX_test_knn, y_test_knn = load_data(test_dir, extract_hog)\n\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train_knn, y_train_knn)\npred_knn = knn_model.predict(X_test_knn)\nprint(f\" k-NN 70 (HoG): {accuracy_score(y_test_knn, pred_knn):.2f}\")\n\n# === AdaBoost (LBP) ===\nX_train_ada, y_train_ada = load_data(train_dir, extract_lbp)\nX_test_ada, y_test_ada = load_data(test_dir, extract_lbp)\n\nada_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50)\nada_model.fit(X_train_ada, y_train_ada)\npred_ada = ada_model.predict(X_test_ada)\nprint(f\" AdaBoost 70 (LBP): {accuracy_score(y_test_ada, pred_ada):.2f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:03:15.475151Z","iopub.execute_input":"2025-04-06T12:03:15.475472Z","iopub.status.idle":"2025-04-06T12:07:21.483353Z","shell.execute_reply.started":"2025-04-06T12:03:15.475451Z","shell.execute_reply":"2025-04-06T12:07:21.482617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(y_true, y_pred, title):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Infected\", \"Infected\"],\n                yticklabels=[\"Not Infected\", \"Infected\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(f\"Confusion Matrix: {title}\")\n    plt.show()\n\nplot_confusion_matrix(y_test_nb, pred_nb, \"Naive Bayes (HSV Histogram)\")\n\nplot_confusion_matrix(y_test_knn, pred_knn, \"k-NN (HoG)\")\n\nplot_confusion_matrix(y_test_ada, pred_ada, \"AdaBoost (LBP)\")\n\n\ndef visualize_color_hist(image_path):\n    image = cv2.imread(image_path)\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    hist_h = cv2.calcHist([hsv], [0], None, [256], [0, 256])\n    hist_s = cv2.calcHist([hsv], [1], None, [256], [0, 256])\n    hist_v = cv2.calcHist([hsv], [2], None, [256], [0, 256])\n\n    plt.figure(figsize=(10, 4))\n    plt.subplot(1, 3, 1)\n    plt.plot(hist_h, color='red')\n    plt.title('H Channel')\n\n    plt.subplot(1, 3, 2)\n    plt.plot(hist_s, color='green')\n    plt.title('S Channel')\n\n    plt.subplot(1, 3, 3)\n    plt.plot(hist_v, color='blue')\n    plt.title('V Channel')\n\n    plt.suptitle(\"HSV Histogram\")\n    plt.show()\n\nsample_image = os.path.join(train_dir, \"infected\", os.listdir(os.path.join(train_dir, \"infected\"))[0])\nvisualize_color_hist(sample_image)\n\n\ndef visualize_hog(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    features, hog_image = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n                              feature_vector=True, visualize=True)\n    \n    plt.figure(figsize=(6, 3))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(\"Original Image\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(hog_image, cmap=\"hot\")\n    plt.title(\"HoG Features\")\n\n    plt.show()\n\nvisualize_hog(sample_image)\n\n\ndef visualize_lbp(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (128, 128))\n    lbp_image = local_binary_pattern(image, P=8, R=1, method='uniform')\n\n    plt.figure(figsize=(6, 3))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(\"Original Image\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(lbp_image, cmap=\"gray\")\n    plt.title(\"LBP Features\")\n\n    plt.show()\n\nvisualize_lbp(sample_image)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:00:48.37842Z","iopub.execute_input":"2025-04-06T12:00:48.378726Z","iopub.status.idle":"2025-04-06T12:00:50.578067Z","shell.execute_reply.started":"2025-04-06T12:00:48.378704Z","shell.execute_reply":"2025-04-06T12:00:50.57722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef print_metrics(y_true, y_pred, model_name):\n    print(f\" Wyniki dla: {model_name}\")\n    print(classification_report(y_true, y_pred, target_names=[\"Not Infected\", \"Infected\"]))\n    print(\"-\" * 50)\n\nprint_metrics(y_test_nb, pred_nb, \"Naive Bayes (HSV Histogram)\")\nprint_metrics(y_test_knn, pred_knn, \"k-NN (HoG)\")\nprint_metrics(y_test_ada, pred_ada, \"AdaBoost (LBP)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:01:03.289797Z","iopub.execute_input":"2025-04-06T12:01:03.290131Z","iopub.status.idle":"2025-04-06T12:01:03.3284Z","shell.execute_reply.started":"2025-04-06T12:01:03.290104Z","shell.execute_reply":"2025-04-06T12:01:03.32763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ndef plot_roc_curve(y_true, y_scores, model_name):\n    fpr, tpr, _ = roc_curve(y_true, y_scores)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(6, 5))\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(f\"ROC Curve: {model_name}\")\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n# Naive Bayes\ny_scores_nb = nb_model.predict_proba(X_test_nb)[:, 1]\nplot_roc_curve(y_test_nb, y_scores_nb, \"Naive Bayes (HSV Histogram)\")\n\n# k-NN\ny_scores_knn = knn_model.predict_proba(X_test_knn)[:, 1]\nplot_roc_curve(y_test_knn, y_scores_knn, \"k-NN (HoG)\")\n\n# AdaBoost\ny_scores_ada = ada_model.predict_proba(X_test_ada)[:, 1]\nplot_roc_curve(y_test_ada, y_scores_ada, \"AdaBoost (LBP)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:01:17.574463Z","iopub.execute_input":"2025-04-06T12:01:17.574747Z","iopub.status.idle":"2025-04-06T12:01:18.707129Z","shell.execute_reply.started":"2025-04-06T12:01:17.574725Z","shell.execute_reply":"2025-04-06T12:01:18.706185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}